{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from nltk import sent_tokenize\n",
    "from keybert import KeyBERT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import time\n",
    "import copy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>accessiblecomputing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>anarchism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>afghanistanhistory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>afghanistangeography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>afghanistanpeople</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                  Word\n",
       "0      0   accessiblecomputing\n",
       "1      1             anarchism\n",
       "2      2    afghanistanhistory\n",
       "3      3  afghanistangeography\n",
       "4      4     afghanistanpeople"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "data = pd.read_csv('Index_words_eng.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = [0, 50]\n",
    "n = list(data.Index)[INDEX[0] : INDEX[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_corpus(index: list or tuple =[0,10], corpus:list = []) -> None:\n",
    "    '''Чтение файлов с текстами собирая их в масси для последущих манипуляций'''\n",
    "    index = list(data.Index)[index[0]: index[1]]\n",
    "    for i in index:\n",
    "        with open(f\"dataset_eng/{i}.txt\", 'r') as fl:\n",
    "            text = fl.read().lower()\n",
    "            text = re.sub(r'/(style=\")([a-zA-Z0-9:;\\.\\s\\(\\)\\-\\,]*)(\")/gi', '', text)\n",
    "            text = re.sub(r'ref|url|link|title|aa|url', '', text)\n",
    "            text = re.sub(r\"title\", '', text)\n",
    "            text = re.sub(r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»\"\"‘’]))', '', text)\n",
    "            text = re.sub(r\"[^a-zA-Z\\.]+\", \" \", text)\n",
    "       \n",
    "        corpus.append(remove_stopwords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_words(corpus) -> list:\n",
    "    \"\"\"Выделение ключевых слов с использованием BERT\"\"\"\n",
    "    res = []\n",
    "    for text in corpus:\n",
    "        try:\n",
    "            model = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "            keywords = model.extract_keywords(text, keyphrase_length=2, use_maxsum=True)\n",
    "            [keywords.append(i) for i in model.extract_keywords(text, keyphrase_length=1, use_maxsum=True)];\n",
    "        except Exception as e:\n",
    "            #print(e)\n",
    "            info = e\n",
    "            keywords = ['None' ] * 10\n",
    "        res.append(keywords)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_DataFrame(data:pd.DataFrame, result, index) -> pd.DataFrame:\n",
    "    return pd.DataFrame({i:j for i,j in zip(list(data.loc[index[0]:index[1], 'Word']), result)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram_tfidf(corpus, res, n= 4) -> None:\n",
    "    \"\"\"ИСпользование n-Grams & TF-IDf\"\"\"\n",
    "    for index_text, text in enumerate(corpus):\n",
    "        size = (1,1)\n",
    "        text = re.sub(r\"shell|redirect|category\", ' ', text)\n",
    "        data = []\n",
    "        \n",
    "        \n",
    "        x2_variaons = {i : TfidfVectorizer(ngram_range = (i, i)).fit_transform(corpus)  for i in range(2, n+1)}\n",
    "        \n",
    "        \n",
    "        for i in range(2, n + 1):\n",
    "            size = (i, i)\n",
    "            vectorizer = CountVectorizer(ngram_range =size) \n",
    "            try:\n",
    "                X1 = vectorizer.fit_transform(sent_tokenize(text))  \n",
    "                features = (vectorizer.get_feature_names()) \n",
    "\n",
    "                # Applying TFIDF \n",
    "                # You can still get n-grams here \n",
    "#                 vectorizer = TfidfVectorizer(ngram_range = size) \n",
    "#                 X2 = vectorizer.fit_transform(corpus)\n",
    "                X2 = x2_variaons[i]\n",
    "#                 scores = (X2.toarray()) \n",
    "\n",
    "                # Getting top ranking features \n",
    "                sums = X2.sum(axis = 0) \n",
    "\n",
    "                for col, term in enumerate(features): \n",
    "                    data.append( (term, sums[0, col] )) \n",
    "            except Exception as e:\n",
    "                info = e\n",
    "                #print(e)\n",
    "        ranking = pd.DataFrame(data, columns = ['term', 'rank']) \n",
    "        words = (ranking.sort_values('rank', ascending = False)) \n",
    "        [res[index_text].append(_) for _ in list(words.head().term.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignment_of_pillars(example_output) -> None:\n",
    "    \"\"\"Выравнивание всех колонок по длине для построение датафрейма\"\"\"\n",
    "    for index, i in enumerate(example_output):\n",
    "        if len(i) < max([len(i) for i in example_output]):\n",
    "            while len(i)< max([len(i) for i in example_output]):\n",
    "                example_output[index].append('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_crossing(arg:list) -> list:\n",
    "    \"\"\"Группировка ключевых n-Gramm тайтла по общему слову\"\"\"\n",
    "    tmp = []\n",
    "    for i in arg:\n",
    "        test = re.sub(r'shell|category|redirect', '', i)\n",
    "        if len(test) > 0:\n",
    "            if len(test.split() ) == 1:\n",
    "                tmp.append(re.sub(r'\\s+', '', test))\n",
    "            else :\n",
    "                tmp.append(test)\n",
    "    tmp = list(set(tmp))\n",
    "    result_new = []\n",
    "    for index, el in enumerate(tmp):\n",
    "        test = []\n",
    "        for index_, el_ in enumerate(tmp):\n",
    "            if el_ != 'None' and len(set(el.split()) & set(el_.split())) > 0 :\n",
    "                test.append(el_)\n",
    "                tmp[index_] = 'None'\n",
    "        if len(test) > 0 :\n",
    "            if len(test) > 1 :\n",
    "                result_new.append(set(test))\n",
    "            else:\n",
    "                result_new.append(test[0])\n",
    "    return result_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognazie_spam(array_words:list) -> list:\n",
    "    \"\"\"Поиск неевалидной информации(которая не относится к терминам)\"\"\"\n",
    "    result = []\n",
    "    for  el in array_words:\n",
    "        flag = True\n",
    "        if type(el) == set:\n",
    "            text = \" \".join(el)\n",
    "            doc = nlp(text)\n",
    "            for ent in doc.ents:\n",
    "                flag = False\n",
    "                break\n",
    "        if flag:\n",
    "            result.append(el)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.06178903579711914 append_corpus ---\n",
      "--- 78.23599338531494 corpus_with_key_words ---\n",
      "--- 7.465719699859619 n_gram_tfidf ---\n",
      "--- 0.4700205326080322 recognazie_spam ---\n",
      "0 50\n"
     ]
    }
   ],
   "source": [
    "from_ = 0\n",
    "for to in np.arange(50, len(n)+ 1, 50):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    corpus = []\n",
    "    index= [from_, to]\n",
    "    \n",
    "    append_corpus(index=index, corpus=corpus)\n",
    "    \n",
    "    print(\"--- %s append_corpus ---\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n",
    "\n",
    "    \n",
    "    corpus_with_key_words = key_words(corpus)\n",
    "    \n",
    "    print(\"--- %s corpus_with_key_words ---\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n",
    "    \n",
    "    \n",
    "    n_gram_tfidf(corpus=corpus, res = corpus_with_key_words)\n",
    "    \n",
    "    print(\"--- %s n_gram_tfidf ---\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for index, el  in enumerate(corpus_with_key_words):\n",
    "        corpus_with_key_words[index] = recognazie_spam(group_crossing(el))\n",
    "    \n",
    "    print(\"--- %s recognazie_spam ---\" % (time.time() - start_time))\n",
    "\n",
    "    \n",
    "    print(from_, to)\n",
    "    from_= to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_output = copy.deepcopy(corpus_with_key_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_of_pillars(example_output=example_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_DataFrame(data=data, result=example_output, index=[INDEX[0], INDEX[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accessiblecomputing</th>\n",
       "      <th>anarchism</th>\n",
       "      <th>afghanistanhistory</th>\n",
       "      <th>afghanistangeography</th>\n",
       "      <th>afghanistanpeople</th>\n",
       "      <th>afghanistancommunications</th>\n",
       "      <th>afghanistantransportations</th>\n",
       "      <th>afghanistanmilitary</th>\n",
       "      <th>afghanistantransnationalissues</th>\n",
       "      <th>assistivetechnology</th>\n",
       "      <th>...</th>\n",
       "      <th>aynrand</th>\n",
       "      <th>alexanderthegreat</th>\n",
       "      <th>anchoragealaska</th>\n",
       "      <th>argumentforms</th>\n",
       "      <th>argumentsfortheexistenceofgod</th>\n",
       "      <th>anarchy</th>\n",
       "      <th>asciiart</th>\n",
       "      <th>academyawards</th>\n",
       "      <th>academyawards/bestpicture</th>\n",
       "      <th>austrialanguage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{camelcase unprintworthy, accessibility camelc...</td>\n",
       "      <td>long roderick</td>\n",
       "      <td>history</td>\n",
       "      <td>None</td>\n",
       "      <td>demographics</td>\n",
       "      <td>communications</td>\n",
       "      <td>None</td>\n",
       "      <td>camelcase</td>\n",
       "      <td>{relations, foreign relations}</td>\n",
       "      <td>{technology, technology camelcase, assistive t...</td>\n",
       "      <td>...</td>\n",
       "      <td>ayn</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{logical form camelcase, logical form, form, l...</td>\n",
       "      <td>{existence god camelcase, existence god, god c...</td>\n",
       "      <td>{anarchy, anarchy camelcase}</td>\n",
       "      <td>ascii</td>\n",
       "      <td>None</td>\n",
       "      <td>{subpage, best picture camelcase subpage, came...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>michael editor stears</td>\n",
       "      <td>camelcase</td>\n",
       "      <td>None</td>\n",
       "      <td>camelcase</td>\n",
       "      <td>camelcase</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>camelcase</td>\n",
       "      <td>camelcase</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>camelcase</td>\n",
       "      <td>camelcase</td>\n",
       "      <td>None</td>\n",
       "      <td>{best picture, best}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>capitalist</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>assistive</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>camelcase</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>liberalism</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>century anarchists</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 accessiblecomputing              anarchism  \\\n",
       "0  {camelcase unprintworthy, accessibility camelc...          long roderick   \n",
       "1                                               None  michael editor stears   \n",
       "2                                               None             capitalist   \n",
       "3                                               None             liberalism   \n",
       "4                                               None     century anarchists   \n",
       "\n",
       "  afghanistanhistory afghanistangeography afghanistanpeople  \\\n",
       "0            history                 None      demographics   \n",
       "1          camelcase                 None         camelcase   \n",
       "2               None                 None              None   \n",
       "3               None                 None              None   \n",
       "4               None                 None              None   \n",
       "\n",
       "  afghanistancommunications afghanistantransportations afghanistanmilitary  \\\n",
       "0            communications                       None           camelcase   \n",
       "1                 camelcase                       None                None   \n",
       "2                      None                       None                None   \n",
       "3                      None                       None                None   \n",
       "4                      None                       None                None   \n",
       "\n",
       "   afghanistantransnationalissues  \\\n",
       "0  {relations, foreign relations}   \n",
       "1                       camelcase   \n",
       "2                            None   \n",
       "3                            None   \n",
       "4                            None   \n",
       "\n",
       "                                 assistivetechnology  ... aynrand  \\\n",
       "0  {technology, technology camelcase, assistive t...  ...     ayn   \n",
       "1                                          camelcase  ...    None   \n",
       "2                                          assistive  ...    None   \n",
       "3                                               None  ...    None   \n",
       "4                                               None  ...    None   \n",
       "\n",
       "  alexanderthegreat anchoragealaska  \\\n",
       "0              None            None   \n",
       "1              None            None   \n",
       "2              None            None   \n",
       "3              None            None   \n",
       "4              None            None   \n",
       "\n",
       "                                       argumentforms  \\\n",
       "0  {logical form camelcase, logical form, form, l...   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                       argumentsfortheexistenceofgod  \\\n",
       "0  {existence god camelcase, existence god, god c...   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                        anarchy   asciiart academyawards  \\\n",
       "0  {anarchy, anarchy camelcase}      ascii          None   \n",
       "1                     camelcase  camelcase          None   \n",
       "2                          None       None          None   \n",
       "3                          None       None          None   \n",
       "4                          None       None          None   \n",
       "\n",
       "                           academyawards/bestpicture austrialanguage  \n",
       "0  {subpage, best picture camelcase subpage, came...            None  \n",
       "1                               {best picture, best}            None  \n",
       "2                                          camelcase            None  \n",
       "3                                               None            None  \n",
       "4                                               None            None  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['long roderick',\n",
       " 'michael editor stears',\n",
       " 'capitalist',\n",
       " 'liberalism',\n",
       " 'century anarchists',\n",
       " 'postcolonialism',\n",
       " 'counterculture',\n",
       " 'fascists']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_with_key_words[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}